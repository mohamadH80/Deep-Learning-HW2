{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Section Z: Import Libraries"
      ],
      "metadata": {
        "id": "uz_6HMyHFLlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "from scipy.signal import convolve2d\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "itWQZXIuFQZu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Section A: Dataset Loading"
      ],
      "metadata": {
        "id": "B9967R2-bSoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MNIST_loaders(train_batch_size, test_batch_size):\n",
        "    mu_mnist = 0.1307\n",
        "    sig_mnist = 0.3081\n",
        "    # In PyTorch, a transform object is an instance of a class that defines a data transformation\n",
        "    transform = Compose([\n",
        "        ToTensor(), # Convert data to tensor\n",
        "        Normalize((mu_mnist,), (sig_mnist,)), # Normalise data\n",
        "        Lambda(lambda x: torch.flatten(x)) # flatten data\n",
        "        ])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        MNIST('./data/', train=True, download=True, transform=transform),\n",
        "        batch_size=train_batch_size, shuffle=True\n",
        "        )\n",
        "        # shuffling is not important in evaluation!\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        MNIST('./data/', train=False, download=True, transform=transform),\n",
        "        batch_size=test_batch_size, shuffle=False\n",
        "        )\n",
        "    \"\"\" DataLoader object description\n",
        "     The primary purpose of a DataLoader is to take a dataset and provide batches of data to the model.\n",
        "     It handles the process of creating batches, shuffling the data (if specified),\n",
        "     and parallelizing data loading using multiple workers to improve efficiency.\n",
        "    \"\"\"\n",
        "    return train_loader, test_loader\n",
        "\n",
        "train_loader, test_loader = MNIST_loaders(50000, 10000)\n",
        "\n"
      ],
      "metadata": {
        "id": "XSYxWY7CFic6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751f15b5-f15a-48ce-a526-b9de5e4594e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 108351062.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 25529124.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 29271260.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5929202.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Section B: Generating Data"
      ],
      "metadata": {
        "id": "0U1He5caHWCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def overlay_labels_on_images(images, labels):\n",
        "    \"\"\"Replace the first 10 pixels of images with one-hot-encoded labels\n",
        "    \"\"\"\n",
        "    num_images = images.shape[0] # Get the number of images in the batch\n",
        "    data = images.clone() # Clone the input images to avoid modifying the original data\n",
        "\n",
        "    data[:, :10] *= 0.0 # Set the values of the first 10 pixels to 0.0\n",
        "\n",
        "    # For each image, set the pixel corresponding to the one-hot-encoded label to the maximum value in the original image\n",
        "    data[range(num_images), labels] = images.max()\n",
        "    return data\n",
        "\n",
        "\n",
        "images_train, labels_train = next(iter(train_loader)) # converts the train_loader into an iterator\n",
        "images_train, labels_train = images.cuda(), labels.cuda() # Move to GPU\n",
        "images_test, labels_test = next(iter(test_loader)) # test data\n",
        "images_test, labels_test = images_test.cuda(), labels_test.cuda() # Move to GPU\n",
        "\n",
        "images_pos = overlay_labels_on_images(images_train, labels)\n",
        "# Generate negative data\n",
        "rnd = torch.randperm(images.size(0))\n",
        "images_neg = overlay_labels_on_images(images_train, labels[rnd])\n"
      ],
      "metadata": {
        "id": "jgKj6BIaHbqF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Section C: Implement Network"
      ],
      "metadata": {
        "id": "4hQr63QSf0zL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, dims):\n",
        "        super().__init__()\n",
        "        self.layers = []\n",
        "        for d in range(len(dims) - 1):\n",
        "            self.layers += [Layer(dims[d], dims[d + 1]).cuda()]\n",
        "    \"\"\"\n",
        "    The paper mentions some techniques like accumulating \"goodness\" scores for each\n",
        "    possible class label and picking the one with the highest score. We could use\n",
        "    this goodness measure to get a predicted label and compare to the true label.\n",
        "    \"\"\"\n",
        "\n",
        "    def predict(self, x):\n",
        "        goodness_per_label = []\n",
        "        for label in range(10):\n",
        "            h = overlay_labels_on_images(x, label)\n",
        "            layers_goodness = []\n",
        "            for layer in self.layers:\n",
        "                h = layer.forward(h)\n",
        "                layers_goodness += [h.pow(2).mean(1)]\n",
        "            goodness_per_label += [sum(layers_goodness).unsqueeze(1)]\n",
        "        goodness_per_label = torch.cat(goodness_per_label, 1)\n",
        "        return goodness_per_label.argmax(1)\n",
        "\n",
        "    def train(self, x_pos, x_neg):\n",
        "        itr_pos = x_pos.clone()\n",
        "        itr_neg = x_neg.clone()\n",
        "        for layer in self.layers:\n",
        "            itr_pos, itr_neg = layer.train(itr_pos, itr_neg)\n",
        "\n",
        "class Layer(nn.Linear):\n",
        "    def __init__(self, in_features, out_features,\n",
        "                 bias=True, device=None, dtype=None):\n",
        "        super().__init__(in_features, out_features, bias, device, dtype)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.opt = Adam(self.parameters(), lr=0.03)\n",
        "        self.threshold = 2.0\n",
        "        self.num_epochs = 100\n",
        "\n",
        "    def forward(self, x):\n",
        "        xn = x / (1e-5 + x.norm(2, 1, keepdim=True))\n",
        "        xn = x / x.size(1)\n",
        "        nxt = torch.mm(xn, self.weight.T) + self.bias.unsqueeze(0)\n",
        "        return self.relu(nxt)\n",
        "\n",
        "\n",
        "    def train(self, x_pos, x_neg):\n",
        "        for i in tqdm(range(self.num_epochs)):\n",
        "          # goodness for each data\n",
        "            g_pos = self.forward(x_pos).pow(2).sum(1)\n",
        "            g_neg = self.forward(x_neg).pow(2).sum(1)\n",
        "          # loss for each data\n",
        "            lp = torch.log(1 + torch.exp(-g_pos + self.threshold))\n",
        "            ln = torch.log(1 + torch.exp(g_neg - self.threshold))\n",
        "            loss = torch.cat([lp, ln]).mean()\n",
        "          # optimization\n",
        "            self.opt.zero_grad()\n",
        "            loss.backward()\n",
        "            self.opt.step()\n",
        "        return self.forward(x_pos).detach(), self.forward(x_neg).detach()"
      ],
      "metadata": {
        "id": "3ho37HW1Snkb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Section D: Results"
      ],
      "metadata": {
        "id": "ce9CjSTxgC2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net([784, 2000, 2000])\n",
        "net.train(images_pos, images_neg)\n",
        "\n",
        "x = net.predict(images).eq(labels).float().mean().item()\n",
        "print('train error:', 1.0 - x)\n",
        "print('train accuracy:', x)\n",
        "\n",
        "\n",
        "y = net.predict(images_test).eq(labels_test).float().mean().item()\n",
        "print('test error:', 1.0 - y)\n",
        "print('test error:', y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "8YhFSIdff0cA",
        "outputId": "eb8929b7-3f6c-44a5-a37b-aa61bd95df18"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7c64cf4cdd7e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train error:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Net' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unsupervised Learning**\n",
        "\n",
        "\n",
        "Section A: Define a Proper Mask"
      ],
      "metadata": {
        "id": "ZLx6ptpHbjbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The method for generating masks for negative data mentioned by Geoffrey Hinton in the article\n",
        "def mask_gen(itr = 10):\n",
        "    random_image = np.random.randint(2, size=(28,28)).squeeze().astype(np.float32)\n",
        "    blur_filter_horizontal = np.array([[0, 0, 0], [0.25, 0.5, 0.25], [0, 0, 0]])\n",
        "    blur_filter_vertical = blur_filter_horizontal.T\n",
        "    for i in range(itr):\n",
        "        random_image = convolve2d(random_image, blur_filter_vertical, mode='same', boundary='symm')\n",
        "        random_image = convolve2d(random_image, blur_filter_horizontal, mode='same', boundary='symm')\n",
        "    # make the mask binerize\n",
        "    mask = (random_image > 0.5).astype(np.float32)\n",
        "    return mask\n",
        "\n",
        "def show_image(x):\n",
        "    x = x.squeeze()\n",
        "    plt.imshow(x, cmap=\"gray\")\n",
        "    plt.show()\n",
        "\n",
        "show_image(mask_gen())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "1JqSWyuK6KVY",
        "outputId": "36313ce2-fdb8-4115-d2ca-743b2d71afaf"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_negative_batch(batch):\n",
        "    mask = mask_gen(8) # mask with 8\n",
        "    # permute batch twice\n",
        "    indexes1 = torch.randperm(batch.shape[0])\n",
        "    indexes2 = torch.randperm(batch.shape[0])\n",
        "    batch_perm1 = batch[indexes1]\n",
        "    batch_perm2 = batch[indexes2]\n",
        "    # apply the mask for each batch\n",
        "    masked_batch_perm1 = batch_perm1 * mask\n",
        "    masked_batch_perm2 = batch_perm2 * (1-mask)\n",
        "    # add masked batches\n",
        "    hybrid_images = masked_batch_perm2 + masked_batch_perm1\n",
        "    return hybrid_images"
      ],
      "metadata": {
        "id": "oYhY6u3WADLp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class Layer(nn.Linear):\n",
        "#     def __init__(self, in_features, out_features,\n",
        "#                  bias=True, device=None, dtype=None):\n",
        "#         super().__init__(in_features, out_features, bias, device, dtype)\n",
        "#         self.relu = torch.nn.ReLU()\n",
        "#         self.opt = Adam(self.parameters(), lr=0.03)\n",
        "#         self.threshold = 2.0\n",
        "#         self.num_epochs = 1000\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         xn = x / (1e-5 + x.norm(2, 1, keepdim=True))\n",
        "#         xn = x / x.size(1)\n",
        "#         nxt = torch.mm(xn, self.weight.T) + self.bias.unsqueeze(0)\n",
        "#         return self.relu(nxt)\n",
        "\n",
        "\n",
        "#     def train(self, x_pos, x_neg):\n",
        "#         for i in tqdm(range(self.num_epochs)):\n",
        "#           # goodness for each data\n",
        "#             g_pos = self.forward(x_pos).pow(2).sum(1)\n",
        "#             g_neg = self.forward(x_neg).pow(2).sum(1)\n",
        "#           # loss for each data\n",
        "#             lp = torch.log(1 + torch.exp(-g_pos + self.threshold))\n",
        "#             ln = torch.log(1 + torch.exp(g_neg - self.threshold))\n",
        "#             loss = torch.cat([lp, ln]).mean()\n",
        "#           # optimization\n",
        "#             self.opt.zero_grad()\n",
        "#             loss.backward()\n",
        "#             self.opt.step()\n",
        "#         return self.forward(x_pos).detach(), self.forward(x_neg).detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# class UnLayer(nn.Linear):\n",
        "#     def __init__(self, in_features, out_features,\n",
        "#                  bias=True, device=None, dtype=None):\n",
        "#         super().__init__(in_features, out_features, bias, device, dtype)\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.opt = Adam(self.parameters(), lr=0.03)\n",
        "#         self.threshold = 2.0\n",
        "#         self.num_epochs = 1000\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         xn = x / (1e-5 + x.norm(2, 1, keepdim=True))\n",
        "#         xn = x / x.size(1)\n",
        "#         nxt = torch.mm(xn, self.weight.T) + self.bias.unsqueeze(0)\n",
        "#         return self.relu(nxt)\n",
        "\n",
        "#     def train(self, x_pos, x_neg):\n",
        "#         for i in tqdm(range(self.num_epochs)):\n",
        "#           # goodness for each data\n",
        "#             g_pos = self.forward(x_pos).pow(2).sum(1)\n",
        "#             g_neg = self.forward(x_neg).pow(2).sum(1)\n",
        "#           # loss for each data\n",
        "#             lp = torch.log(1 + torch.exp(-g_pos + self.threshold))\n",
        "#             ln = torch.log(1 + torch.exp(g_neg - self.threshold))\n",
        "#             loss = torch.cat([lp, ln]).mean()\n",
        "#           # optimization\n",
        "#             self.opt.zero_grad()\n",
        "#             loss.backward()\n",
        "#             self.opt.step()\n",
        "#         return self.forward(x_pos).detach(), self.forward(x_neg).detach()"
      ],
      "metadata": {
        "id": "lZyVD4o5NTxt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnNet(nn.Module):\n",
        "    def __init__(self, dims):\n",
        "        super().__init__()\n",
        "        self.layers = []\n",
        "        for d in range(len(dims) - 1):\n",
        "            self.layers += [Layer(dims[d], dims[d + 1]).cuda()]\n",
        "\n",
        "    def predict(self,x, softmax_layers):\n",
        "        layers_output = torch.Tensor([]).cuda()\n",
        "        h = x.clone()\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            h = layer.forward(h)\n",
        "            if i in softmax_layers:\n",
        "                layers_output = torch.cat([layers_output,h],1)\n",
        "        return layers_output\n",
        "\n",
        "    def train(self, x_pos, x_neg):\n",
        "        itr_pos = x_pos.clone()\n",
        "        itr_neg = x_neg.clone()\n",
        "        for layer in self.layers:\n",
        "            itr_pos, itr_neg = layer.train(itr_pos, itr_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "X_tdRArtQc0N",
        "outputId": "41eb18c5-2a91-493b-d085-06f90a6a6247"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-946b8e84ff0b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mUnNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Section D: Linear Classifier"
      ],
      "metadata": {
        "id": "r2cVANvMZO08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FFNet(layers = [784,500,500,500,500])\n",
        "\n",
        "model.train(images_pos ,images_neg)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RJ0zM3emZbuq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}